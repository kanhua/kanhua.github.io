<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>3D object detection with Lyft self-driving car data - Kan-Hua Lee</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="/3d-object-detection-with-lyft-self-driving-car-data.html">

        <meta name="author" content="Kan-Hua Lee" />
        <meta name="keywords" content="self-driving car,computer vision" />
        <meta name="description" content="This is my attempt of a past Kaggle competition Lyft 3D Object Detection for Autonomous Vehicles, using the concept of frustum-pointnet to solve this past Kaggle competition. This is an example of the classifed results: Result This work is still in progress. The result does not seem too bad if …" />

        <meta property="og:site_name" content="Kan-Hua Lee" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="3D object detection with Lyft self-driving car data"/>
        <meta property="og:url" content="/3d-object-detection-with-lyft-self-driving-car-data.html"/>
        <meta property="og:description" content="This is my attempt of a past Kaggle competition Lyft 3D Object Detection for Autonomous Vehicles, using the concept of frustum-pointnet to solve this past Kaggle competition. This is an example of the classifed results: Result This work is still in progress. The result does not seem too bad if …"/>
        <meta property="article:published_time" content="2020-03-08" />
            <meta property="article:section" content="Blog" />
            <meta property="article:tag" content="self-driving car" />
            <meta property="article:tag" content="computer vision" />
            <meta property="article:author" content="Kan-Hua Lee" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>




</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
Kan-Hua Lee            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="/pages/about-me.html">
                             About Me
                          </a></li>
                         <li><a href="/pages/toy-projects.html">
                             Toy Projects
                          </a></li>
                        <li class="active">
                            <a href="/category/blog.html">Blog</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/3d-object-detection-with-lyft-self-driving-car-data.html"
                       rel="bookmark"
                       title="Permalink to 3D object detection with Lyft self-driving car data">
                        3D object detection with Lyft self-driving car data
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2020-03-08T21:01:00+09:00"> Sun 08 March 2020</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/self-driving-car.html">self-driving car</a>
        /
	<a href="/tag/computer-vision.html">computer vision</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>This is my attempt of a past Kaggle competition <a href="https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles">Lyft 3D Object Detection for Autonomous Vehicles</a>, using the concept of <a href="http://stanford.edu/~rqi/frustum-pointnets/">frustum-pointnet</a> to solve this past Kaggle competition.</p>
<p>This is an example of the classifed results:
<img src="/images/lyft-3d/demo_image_10.png" alt="camera_image"></p>
<h3>Result</h3>
<p>This work is still in progress. The result does not seem too bad if observing by eye. However, the score is not as good as the baseline score by using image segmentation of top-view lidar data (e.g. <a href="https://www.kaggle.com/meaninglesslives/lyft3d-inference-kernel">this work</a>).
Because this model generates the frustum proposals from camera images, objects behind other objects are not well shown on 2D images, causing some loss in this model. Although this implementation does not exceed the performance of a simple top-view model, I did learn a lot of experience handling pointnet data and computer 3D graphics.</p>
<p><img src="/images/lyft-3d/demo_3d_lidar_10.png" alt="lidar_image"></p>
<h3>The implementation</h3>
<h4>Generate frustum proposal from images</h4>
<p>The outline of the model is below:</p>
<p><img src="/images/lyft-3d/frustum_pointnet_implementation.png" alt="frustum_pointnet_implementation"></p>
<p>Here's some details of the implementation</p>
<h4>Object detection model</h4>
<p>The frustum proposal is generated from a object detector. I trained Fast RCNN-ResNET detector using <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Tensorflow object detection API</a>.</p>
<p>The following image is an example of the image:</p>
<p><img src="/images/lyft-3d/CAM_FRONT_2d_detection.png" alt="frustum_pointnet_implementation"></p>
<p>compared with the point cloud extracted from ground truth:</p>
<p><img src="/images/lyft-3d/CAM_FRONT_from_rgb.png" alt="frustum_pointnet_implementation"></p>
<h4>Frustum extraction</h4>
<p>The frusum proposals was extracted all cameras images of a certain time stamp. These data were saved to a tfrecord files for training a PointNetV1 model. The original paper trained the model for many days. I only trained a few epochs for a few hours because of insuffcient budget.</p>
<h4>PointNetV1</h4>
<p>I altered the code of <a href="http://stanford.edu/~rqi/frustum-pointnets/">frustum-pointnet</a> to train the data via the prepared tfrecord files.</p>
<h3>Analysis and further improvement ideas</h3>
<p>The IoU precision is not satisfactory. The precision score of each IoU levels are:</p>
<p>iou level:0.5, avg precision: 0.01156315990772716</p>
<p>iou level:0.55, avg precision: 0.008525362114315115</p>
<p>iou level:0.6, avg precision: 0.005816150268591333</p>
<p>iou level:0.65, avg precision: 0.0038102846985294658</p>
<p>iou level:0.7, avg precision: 0.0023121225957451587</p>
<p>iou level:0.75, avg precision: 0.001109161883024114</p>
<p>iou level:0.8, avg precision: 0.00016343784202644128</p>
<p>The reason is that this approach generates frustum proposals from 2D images. As a result, object behind another object is misclassified using a 2D object detector, as we can see in the above figures. Also, the averaged precisions drops quite significantly with the IoU levels, indicating that the predicted boxes are not very accurate. Training the PointNet for more epochs would certainly help.</p>
<ol>
<li>Add point cloud proposals using a top-view.</li>
<li>Use image augmentation to make the classes of the data more balanced, this would increase the precisions of the class of objects that have fewer occurrences, such as "pedestrians" or "other vehicles"</li>
</ol>
<h2>Code</h2>
<p>The source code of this project: <a href="https://github.com/kanhua/lyft-3d-main">Source code</a>.</p>
            </div>
            <!-- /.entry-content -->
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/kanhua"><i class="fa fa-github-square fa-lg"></i> github</a></li>
    <li class="list-group-item"><a href="https://www.linkedin.com/in/kanhualee/"><i class="fa fa-linkedin-square fa-lg"></i> linkedin</a></li>
    <li class="list-group-item"><a href="https://medium.com/@kanhua"><i class="fa fa-medium-square fa-lg"></i> medium</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group " id="tags">
    <li class="list-group-item tag-1">
      <a href="/tag/self-driving-car.html">self-driving car</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/computer-vision.html">computer vision</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/physics.html">physics</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/numerical-modeling.html">numerical modeling</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2024 Kan-Hua Lee
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>




</body>
</html>